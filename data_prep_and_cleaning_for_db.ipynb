{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69209066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24db2f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x29e838a5500>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create hopteaming database.\n",
    "db = sqlite3.connect('data/hopteaming.sqlite')\n",
    "cursor = db.cursor()\n",
    "cursor.executescript(\"\"\"\n",
    "DROP TABLE IF EXISTS hopteaming;\n",
    "DROP TABLE IF EXISTS nppes;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c513141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of columns to use for nppes dataset.\n",
    "list_of_nppes_cols = ['NPI',\n",
    "                      'Entity Type Code',\n",
    "                      'Provider Organization Name (Legal Business Name)',\n",
    "                      'Provider Last Name (Legal Name)',\n",
    "                      'Provider First Name',\n",
    "                      'Provider Middle Name',\n",
    "                      'Provider Name Prefix Text',\n",
    "                      'Provider Name Suffix Text',\n",
    "                      'Provider Credential Text',\n",
    "                      'Provider First Line Business Practice Location Address',\n",
    "                      'Provider Second Line Business Practice Location Address',\n",
    "                      'Provider Business Practice Location Address City Name',\n",
    "                      'Provider Business Practice Location Address State Name',\n",
    "                      'Provider Business Practice Location Address Postal Code',\n",
    "                      'Healthcare Provider Taxonomy Code_1',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_1',\n",
    "                      'Healthcare Provider Taxonomy Code_2',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_2',\n",
    "                      'Healthcare Provider Taxonomy Code_3',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_3',\n",
    "                      'Healthcare Provider Taxonomy Code_4',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_4',\n",
    "                      'Healthcare Provider Taxonomy Code_5',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_5',\n",
    "                      'Healthcare Provider Taxonomy Code_6',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_6',\n",
    "                      'Healthcare Provider Taxonomy Code_7',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_7',\n",
    "                      'Healthcare Provider Taxonomy Code_8',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_8',\n",
    "                      'Healthcare Provider Taxonomy Code_9',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_9',\n",
    "                      'Healthcare Provider Taxonomy Code_10',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_10',\n",
    "                      'Healthcare Provider Taxonomy Code_11',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_11',\n",
    "                      'Healthcare Provider Taxonomy Code_12',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_12',\n",
    "                      'Healthcare Provider Taxonomy Code_13',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_13',\n",
    "                      'Healthcare Provider Taxonomy Code_14',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_14',\n",
    "                      'Healthcare Provider Taxonomy Code_15',\n",
    "                      'Healthcare Provider Primary Taxonomy Switch_15']\n",
    "\n",
    "# List of columns to pivot NPPES dataset on.\n",
    "pivot_cols = ['Healthcare Provider Taxonomy Code_1',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_1',\n",
    "            'Healthcare Provider Taxonomy Code_2',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_2',\n",
    "            'Healthcare Provider Taxonomy Code_3',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_3',\n",
    "            'Healthcare Provider Taxonomy Code_4',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_4',\n",
    "            'Healthcare Provider Taxonomy Code_5',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_5',\n",
    "            'Healthcare Provider Taxonomy Code_6',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_6',\n",
    "            'Healthcare Provider Taxonomy Code_7',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_7',\n",
    "            'Healthcare Provider Taxonomy Code_8',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_8',\n",
    "            'Healthcare Provider Taxonomy Code_9',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_9',\n",
    "            'Healthcare Provider Taxonomy Code_10',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_10',\n",
    "            'Healthcare Provider Taxonomy Code_11',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_11',\n",
    "            'Healthcare Provider Taxonomy Code_12',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_12',\n",
    "            'Healthcare Provider Taxonomy Code_13',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_13',\n",
    "            'Healthcare Provider Taxonomy Code_14',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_14',\n",
    "            'Healthcare Provider Taxonomy Code_15',\n",
    "            'Healthcare Provider Primary Taxonomy Switch_15']\n",
    "\n",
    "# Dictionary for renaming columns in merged dataset.\n",
    "rename_cols_dict = {'provider_organization_name_(legal_business_name)':'organization_name',\n",
    "                    'provider_name_prefix_text':'name_prefix',\n",
    "                    'provider_first_name':'first_name',\n",
    "                    'provider_middle_name':'middle_name',\n",
    "                    'provider_last_name_(legal_name)':'last_name',\n",
    "                    'provider_name_suffix_text':'name_suffix',\n",
    "                    'provider_credential_text':'credentials',\n",
    "                    'provider_first_line_business_practice_location_address':'address_first_line',\n",
    "                    'provider_second_line_business_practice_location_address':'address_second_line',\n",
    "                    'provider_business_practice_location_address_city_name':'city',\n",
    "                    'provider_business_practice_location_address_state_name':'state',\n",
    "                    'provider_business_practice_location_address_postal_code':'zipcode',\n",
    "                    'usps_zip_pref_city':'cbsa_city',\n",
    "                    'usps_zip_pref_state':'cbsa_state',\n",
    "                    'code':'taxonomy_code',\n",
    "                    'grouping':'taxonomy_code_grouping',\n",
    "                    'classification':'taxonomy_code_classification',\n",
    "                    'specialization':'taxonomy_code_specialization',\n",
    "                    'definition':'taxonomy_code_definition',\n",
    "                    'display_name':'taxonomy_code_display_name',\n",
    "                    'section':'taxonomy_code_section'}\n",
    "\n",
    "\n",
    "# (preliminary) Final column ordering.\n",
    "final_column_ordering = ['npi', \n",
    "                         'entity_type_code', \n",
    "                         'organization_name',\n",
    "                         'name_prefix', \n",
    "                         'first_name', \n",
    "                         'middle_name',\n",
    "                         'last_name',\n",
    "                         'name_suffix',\n",
    "                         'credentials', \n",
    "                         'address_first_line', \n",
    "                         'address_second_line', \n",
    "                         'city',\n",
    "                         'state', \n",
    "                         'zipcode', \n",
    "                         'cbsa',\n",
    "                         'cbsa_city',\n",
    "                         'cbsa_state',\n",
    "                         'taxonomy_code',\n",
    "                         'taxonomy_code_grouping',\n",
    "                         'taxonomy_code_classification',\n",
    "                         'taxonomy_code_specialization',\n",
    "                         'taxonomy_code_display_name',\n",
    "                         'taxonomy_code_section']\n",
    "\n",
    "\n",
    "# Read in taxonomy code classification dataset.\n",
    "classifications = pd.read_csv('data/nucc_taxonomy_220.csv')\n",
    "\n",
    "# Read in zip to cbsa dataset. Change zipcode column to string for ease of merge later.\n",
    "cbsa = pd.read_csv('data/ZIP_CBSA_122021.csv', \n",
    "                   usecols = ['zip',\n",
    "                              'cbsa',\n",
    "                              'usps_zip_pref_city',\n",
    "                              'usps_zip_pref_state',\n",
    "                              'tot_ratio'])\n",
    "\n",
    "cbsa['zip'] = cbsa['zip'].astype(str)\n",
    "\n",
    "# Select rows where tot_ratio of cbsa to zip is the max for that zip.\n",
    "cbsa = cbsa[cbsa.groupby(['zip'])['tot_ratio'].transform(max) == cbsa['tot_ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b639ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01513d09bb4c4536af93f0b90e348480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in chunks from nppes csv file as chunks.\n",
    "header = True\n",
    "for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20220213.csv', \n",
    "                              usecols = list_of_nppes_cols, \n",
    "                              chunksize = 100000,\n",
    "                             low_memory = False)):\n",
    "    \n",
    "    # Filter chunk for practice locations in TN only.\n",
    "    chunk = chunk[chunk['Provider Business Practice Location Address State Name'] == 'TN']\n",
    "    \n",
    "\n",
    "    # Create two subsets of nppes dataset pivoted by NPI with taxonomy switches and codes and then concatenate together into\n",
    "    # larger subset.\n",
    "    chunk_taxonomy_code_subset = (\n",
    "        pd.concat([chunk.melt(id_vars = 'NPI',\n",
    "                              value_vars = pivot_cols[0:29:2],\n",
    "                              var_name = 'code_number',\n",
    "                              value_name = 'code')\\\n",
    "                   .sort_values(by = 'NPI'),\n",
    "                   chunk.melt(id_vars = 'NPI',\n",
    "                              value_vars = pivot_cols[1:29:2],\n",
    "                              var_name = 'switch_number',\n",
    "                              value_name = 'switch')\\\n",
    "                   .sort_values(by = 'NPI')],\n",
    "                  axis = 1)\n",
    "              )\n",
    "\n",
    "    # Merge the subset dataset back into the larger one.\n",
    "    chunk = (\n",
    "        chunk\\\n",
    "        .drop(pivot_cols, axis = 1)\\\n",
    "        .merge(chunk_taxonomy_code_subset[['NPI','code']]\\\n",
    "        .loc[chunk_taxonomy_code_subset['switch'] == 'Y']\\\n",
    "        .iloc[:,[0,2]]\\\n",
    "        .sort_values('NPI')\\\n",
    "        .set_index('NPI')\\\n",
    "        .reset_index(), \n",
    "               how = 'inner', \n",
    "               on = 'NPI')\n",
    "             )\n",
    "    \n",
    "    # Change zipcode to string to trim.\n",
    "    chunk['Provider Business Practice Location Address Postal Code'] = (\n",
    "        chunk['Provider Business Practice Location Address Postal Code']\\\n",
    "        .astype(str)\\\n",
    "        .apply(lambda x: x[0:5])\n",
    "    )\n",
    "    \n",
    "    # Merge cbsa and classifications dataset to the chunk.\n",
    "    chunk = (\n",
    "        chunk.merge(classifications,\n",
    "                    left_on = 'code',\n",
    "                    right_on = 'Code',\n",
    "                    how = 'inner')\\\n",
    "        .merge(cbsa,\n",
    "               left_on = 'Provider Business Practice Location Address Postal Code',\n",
    "               right_on = 'zip',\n",
    "               how = 'inner')\\\n",
    "        .drop(columns = ['Code',\n",
    "                         'Notes',\n",
    "                         'zip'])\n",
    "    )\n",
    "    \n",
    "    # Rename and reorder all columns.\n",
    "    chunk.columns = [column.lower().replace(' ', '_') for column in chunk.columns]\n",
    "    \n",
    "    chunk = (\n",
    "        chunk\\\n",
    "        .rename(columns = rename_cols_dict)\n",
    "    )\n",
    "    \n",
    "    chunk = chunk[final_column_ordering]\n",
    "    \n",
    "    # Read chunk into sqlite database.\n",
    "    chunk.to_sql('nppes', \n",
    "                 db, \n",
    "                 if_exists = 'append', \n",
    "                 index = False)\n",
    "    \n",
    "    # Write chunk to csv.\n",
    "    chunk.to_csv('data/nppes.csv', \n",
    "                 header = header, \n",
    "                 mode = 'a', \n",
    "                 index = False)\n",
    "    header = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc408fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read back in full nppes dataset but only two rows--npi and entity type code.\n",
    "only_npi_and_et = pd.read_csv('data/nppes.csv', \n",
    "                              usecols = ['npi','entity_type_code'], \n",
    "                              dtype = ('int','int'))\n",
    "\n",
    "# Split these into two datasets for each npi column in hopteaming.\n",
    "from_npi_et = (\n",
    "    only_npi_and_et[['npi','entity_type_code']]\\\n",
    "    .rename(columns = {'entity_type_code':'from_npi_et'})\\\n",
    "    .set_index('npi')\n",
    ")\n",
    "to_npi_et = (\n",
    "    only_npi_and_et[['npi','entity_type_code']]\\\n",
    "    .rename(columns = {'entity_type_code':'to_npi_et'})\\\n",
    "    .set_index('npi')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc81ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97bbeca3104c48d5a14d7a378eeb464d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in chunks from hop_teaming csv file. \n",
    "header = True\n",
    "for chunk in tqdm(pd.read_csv('data/DocGraph_Hop_Teaming_2018.csv', chunksize = 100000)):\n",
    "    \n",
    "    # Merge chunk with npi entity codes.\n",
    "    chunk = (\n",
    "        chunk\\\n",
    "        .set_index('from_npi')\\\n",
    "        .join(from_npi_et,\n",
    "              how = 'inner')\\\n",
    "        .reset_index()\\\n",
    "        .rename(columns = {'index':'from_npi'})\\\n",
    "        .set_index('to_npi')\\\n",
    "        .join(to_npi_et,\n",
    "              how = 'inner')\\\n",
    "        .reset_index()\\\n",
    "        .rename(columns = {'index':'to_npi'})\n",
    "       )\n",
    "    \n",
    "    # Filter based on entity codes.\n",
    "    chunk = (\n",
    "        chunk[(chunk['to_npi_et'] == 2) & (chunk['from_npi_et'] == 1)]\\\n",
    "        .drop(columns = ['to_npi_et','from_npi_et'])\n",
    "    )\n",
    "    \n",
    "    # Filter for transaction count and average day wait and read to sqlite.\n",
    "    chunk = chunk[(chunk['transaction_count'] >= 50) | (chunk['average_day_wait'] < 50)]\n",
    "    \n",
    "    chunk.to_sql('hopteaming', \n",
    "                 db, \n",
    "                 if_exists = 'append', \n",
    "                 index = False)  \n",
    "    \n",
    "    # Write chunk to csv.\n",
    "    chunk.to_csv('data/hopteaming.csv', \n",
    "                 header = header, \n",
    "                 mode = 'a', \n",
    "                 index = False)\n",
    "    header = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
